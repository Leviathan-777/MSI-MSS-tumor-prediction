{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-04-14T21:45:26.006359Z","iopub.status.busy":"2023-04-14T21:45:26.005933Z","iopub.status.idle":"2023-04-14T21:45:38.163875Z","shell.execute_reply":"2023-04-14T21:45:38.162263Z","shell.execute_reply.started":"2023-04-14T21:45:26.006315Z"},"trusted":true},"outputs":[],"source":["import os\n","import tensorflow as tf\n","from tensorflow import keras\n","from sklearn.utils import shuffle\n","import numpy as np\n","from tensorflow.keras.applications.resnet50 import preprocess_input as preprocess_resnet\n","from tensorflow.keras.applications.inception_v3 import preprocess_input as preprocess_inception\n","from tensorflow.keras.applications.inception_resnet_v2 import preprocess_input as preprocess_hybrid\n","from tensorflow.keras.preprocessing import image"]},{"cell_type":"markdown","metadata":{},"source":["Load the models"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-04-14T21:45:38.167367Z","iopub.status.busy":"2023-04-14T21:45:38.166589Z","iopub.status.idle":"2023-04-14T21:45:46.723467Z","shell.execute_reply":"2023-04-14T21:45:46.722095Z","shell.execute_reply.started":"2023-04-14T21:45:38.167323Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," resnet50 (Functional)       (None, 7, 7, 2048)        23587712  \n","                                                                 \n"," global_average_pooling2d (G  (None, 2048)             0         \n"," lobalAveragePooling2D)                                          \n","                                                                 \n","=================================================================\n","Total params: 23,587,712\n","Trainable params: 23,534,592\n","Non-trainable params: 53,120\n","_________________________________________________________________\n"]}],"source":["#Load Resnet50\n","resnet_model = tf.keras.models.load_model(\"../Feature Extraction models/resnet50_model\")\n","#Remove Classifiation Layers\n","resnet50 = tf.keras.models.Sequential(resnet_model.layers[:-5])\n","resnet50.summary()"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-04-14T21:05:55.262398Z","iopub.status.busy":"2023-04-14T21:05:55.261692Z","iopub.status.idle":"2023-04-14T21:06:06.596796Z","shell.execute_reply":"2023-04-14T21:06:06.595348Z","shell.execute_reply.started":"2023-04-14T21:05:55.262362Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," inception_v3 (Functional)   (None, 5, 5, 2048)        21802784  \n","                                                                 \n"," global_average_pooling2d_1   (None, 2048)             0         \n"," (GlobalAveragePooling2D)                                        \n","                                                                 \n","=================================================================\n","Total params: 21,802,784\n","Trainable params: 21,768,352\n","Non-trainable params: 34,432\n","_________________________________________________________________\n"]}],"source":["#Load Inception-V3\n","inceptionv3_model = tf.keras.models.load_model(\"../Feature Extraction models/inceptionv3_model\")\n","#Remove Classifiation Layers\n","inceptionv3 = tf.keras.models.Sequential(inceptionv3_model.layers[:-5])\n","inceptionv3.summary()"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-04-14T21:45:46.725645Z","iopub.status.busy":"2023-04-14T21:45:46.725181Z","iopub.status.idle":"2023-04-14T21:46:08.052250Z","shell.execute_reply":"2023-04-14T21:46:08.050632Z","shell.execute_reply.started":"2023-04-14T21:45:46.725606Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," inception_resnet_v2 (Functi  (None, 5, 5, 1536)       54336736  \n"," onal)                                                           \n","                                                                 \n"," global_average_pooling2d (G  (None, 1536)             0         \n"," lobalAveragePooling2D)                                          \n","                                                                 \n","=================================================================\n","Total params: 54,336,736\n","Trainable params: 54,276,192\n","Non-trainable params: 60,544\n","_________________________________________________________________\n"]}],"source":["#Load Inception-Resnet-V2\n","hybrid_model = tf.keras.models.load_model(\"../Feature Extraction models/hybrid_model\")\n","#Remove Classifiation Layers\n","hybrid = tf.keras.models.Sequential(hybrid_model.layers[:-5])\n","hybrid.summary()"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-04-14T21:46:08.058332Z","iopub.status.busy":"2023-04-14T21:46:08.057943Z","iopub.status.idle":"2023-04-14T21:46:08.072453Z","shell.execute_reply":"2023-04-14T21:46:08.071028Z","shell.execute_reply.started":"2023-04-14T21:46:08.058295Z"},"trusted":true},"outputs":[],"source":["def preprocess_img(img_path, preprocessing_function):\n","    img = image.load_img(img_path, target_size=(224, 224))\n","    x = image.img_to_array(img)\n","    x = np.expand_dims(x, axis=0)\n","    x = preprocessing_function(x)\n","    return x\n","\n","def extract_features_from_img(img, model):\n","    # Use the the transfer learning model to extract features\n","    features = model.predict(img)\n","\n","    # Flatten the feature vector\n","    features = features.flatten()\n","\n","    return features\n","\n","def extract_features(path_to_cat, model, preprocessing_function, batch=0, batch_size=0, save_path='model'): #Use batch option to extract parts of the dataset\n","    data_array = ([][])\n","    if(batch>0):\n","        x=batch_size #Number of images to use during feature extraction\n","        start=batch-1\n","        start=start*x #Start posistion of the dataset\n","        start=int(start/2)\n","        stop=int(start+x/2)\n","    else:\n","        x=0\n","        start=0\n","        stop=0\n","    for cat in os.listdir(path_to_cat):\n","        # Defining path to images in category\n","        path_to_images = os.path.join(path_to_cat, cat)\n","        \n","        # Defining labels\n","        if cat == 'MSIMUT':\n","            label = 1\n","        else:\n","            label = 0\n","            \n","        z=-1\n","        # Loop through images in category\n","        for i in os.listdir(path_to_images):\n","            if(batch>0):\n","                z=z+1\n","            if(z<start and start!=0 and batch>0):\n","                continue\n","            if(z==stop and batch>0):\n","                break\n","                \n","            # Path to image\n","            image_path = os.path.join(path_to_images, i)\n","            \n","            # Reading and preprocessing image\n","            x = preprocess_img(image_path, preprocessing_function)\n","            \n","            # Extracting features\n","            features = extract_features_from_img(x, model)\n","            \n","            # Store features and label in our lists\n","            data_array[0].append(features)\n","            data_array[1].append(label)\n","    if(batch>0):\n","        np.save(save_path + '_features_' + str(batch) + \".npy\", data_array[0])\n","        np.save(save_path + '_labels_' + str(batch) + \".npy\", data_array[1])\n","    else:\n","        np.save(save_path + '_features' + \".npy\", data_array[0])\n","        np.save(save_path + '_labels' + \".npy\", data_array[1])"]},{"cell_type":"markdown","metadata":{},"source":["Extract Features from Training Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["path_to_train = \"../Dataset/training\"\n","path_to_test = \"../Dataset/evaluation\"\n","seed = 666 #Use seed to get the results that can be recreated\n","\n","rs_path = \"../Features/resnet50\"\n","\n","inc_path = \"../Features/inceptionv3\"\n","\n","hybrid_path = \"../Features/hybrid\"\n","\n","rs_test_path = \"../Features/resnet50\"\n","\n","inc_test_path = \"../Features/inceptionv3_test\"\n","\n","hybrid_test_path = \"../Features/hybrid_test\""]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#Extract training features using Resnet50\n","extract_features(path_to_train, resnet50, preprocess_resnet, save_path=rs_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#Extract training features using Inception\n","extract_features(path_to_train, inceptionv3, preprocess_inception, save_path=inc_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#Extract training features using Hybrid\n","extract_features(path_to_train, hybrid, preprocess_hybrid, save_path=hybrid_path)"]},{"cell_type":"markdown","metadata":{},"source":["Extract features from evaluation dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#Extract test features using Resnet50\n","extract_features(path_to_test, resnet50, preprocess_resnet, save_path=rs_test_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#Extract test features using Inception\n","extract_features(path_to_test, inceptionv3, preprocess_inception, save_path=inc_test_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#Extract test features using Hybrid\n","extract_features(path_to_test, hybrid, preprocess_hybrid, save_path=hybrid_test_path)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Reshape features and save them to single files. Use only if batch parameter was used!"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Use the functions below only if you used batch parameter and you want to combine the feature files into one file"]},{"cell_type":"code","execution_count":3,"metadata":{"trusted":true},"outputs":[],"source":["def save_to_one_file(train_path, lbl_path, name, num_of_files, num_of_features, num_of_samples):\n","    train_files = [train_path + str(i+1) +\".npy\" for i in range(num_of_files)]\n","    train_lbl = [lbl_path + str(i+1) +\".npy\" for i in range(num_of_files)]\n","    train_X = np.array([np.load(fname) for fname in train_files])\n","    train_X = train_X.reshape(num_of_samples, num_of_features)\n","    train_Y = np.array([np.load(fname) for fname in train_lbl])\n","    train_Y = train_Y.reshape(num_of_samples)\n","    np.save(\"../Features/\" + name + \"_features.npy\", train_X)\n","    np.save(\"../Features/\" + name + \"_labels.npy\", train_Y)"]},{"cell_type":"code","execution_count":5,"metadata":{"trusted":true},"outputs":[],"source":["#Reshape features and save them to one file\n","resnet_features_path = \"../Features/training/resnet_features_\"\n","resnet_lbl_path = \"../Features/training/resnet_labels_\"\n","\n","inception_features_path = \"../Features/training/inceptionv3_features_\"\n","inception_lbl_path = \"../Features/training/inceptionv3_labels_\"\n","\n","hybrid_features_path = \"../Features/training/hybrid_features_\"\n","hybrid_lbl_path = \"../Features/training/hybrid_labels_\"\n","\n","resnet_test_features_path = \"../Features/evaluation/resnet50_test_features_\"\n","resnet_test_lbl_path = \"../Features/evaluation/resnet50_test_labels_\"\n","\n","inception_test_features_path = \"../Features/evaluation/inceptionv3_test_features_\"\n","inception_test_lbl_path = \"../Features/evaluation/inceptionv3_test_labels_\"\n","\n","hybrid_test_features_path = \"../Features/evaluation/hybrid_test_features_\"\n","hybrid_test_lbl_path = \"../Features/evaluation/hybrid_test_labels_\"\n","\n","samples = 60000\n","files = 10\n","tst_files = 2\n","tst_samples=12000"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Save training features to one file\n","save_to_one_file(resnet_features_path, resnet_lbl_path, \"resnet50\", files, 2048, samples)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["save_to_one_file(inception_features_path, inception_lbl_path, \"inceptionv3\",files,2048, samples)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["save_to_one_file(hybrid_features_path, hybrid_lbl_path, \"hybrid\",files,1536, samples)"]},{"cell_type":"code","execution_count":6,"metadata":{"trusted":true},"outputs":[],"source":["#Save test features to one file\n","save_to_one_file(resnet_test_features_path, resnet_test_lbl_path, \"resnet50_test\", tst_files, 2048, tst_samples)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["save_to_one_file(inception_test_features_path, inception_test_lbl_path, \"inceptionv3_test\", tst_files, 2048, tst_samples)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["save_to_one_file(hybrid_test_features_path, hybrid_test_lbl_path, \"hybrid_test\", tst_files, 1536, tst_samples)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"}},"nbformat":4,"nbformat_minor":4}
